#### LLaMA Demo of 7B
- ðŸŽŸModel from: [llama](https://github.com/facebookresearch/llama)
- ðŸ€„Code fromï¼š[pyllama](https://github.com/juncongmoo/pyllama)
- ðŸ“ŒFAQï¼š[FAQ](https://github.com/facebookresearch/llama/blob/main/FAQ.md#2)


#### Run environ
- single GPU: 16GB


#### Use
1. Download the pretrained_model.
    - BitTorrent link: `magnet:?xt=urn:btih:ZXXDAUWYLRUXXBHUYEMS6Q5CE5WA3LVA&dn=LLaMA`
    - The final directory:
        ```text
        .
        â”œâ”€â”€ inference.py
        â”œâ”€â”€ llama
        â”‚   â”œâ”€â”€ generation.py
        â”‚   â”œâ”€â”€ __init__.py
        â”‚   â”œâ”€â”€ model_parallel.py
        â”‚   â”œâ”€â”€ model_single.py
        â”‚   â””â”€â”€ tokenizer.py
        â”œâ”€â”€ LLaMA
        â”‚   â”œâ”€â”€ 7B
        â”‚   â”‚   â”œâ”€â”€ checklist.chk
        â”‚   â”‚   â”œâ”€â”€ consolidated.00.pth
        â”‚   â”‚   â””â”€â”€ params.json
        â”‚   â”œâ”€â”€ tokenizer_checklist.chk
        â”‚   â””â”€â”€ tokenizer.model
        â”œâ”€â”€ requirements.txt
        â””â”€â”€ webapp_single.py
        ```
2. Install the related packages.
    ```shell
    pip install -r requirements.txt
    ```
3. Run
    - Inference by scripts
        ```shell
        python inference.py
        ```
    - Run by Gradio UI
        ```shell
        python webapp_single.py
        ```

4. Gradio Result
   - Open `http://127.0.0.1:7860` to enjoy it.
    <div align="center">
        <img src="./assets/GradioUI.png" width="100%" height="100%">
    </div>
